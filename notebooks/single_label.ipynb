{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a0cae3a9",
      "metadata": {
        "id": "a0cae3a9"
      },
      "outputs": [],
      "source": [
        "MODEL = \"resnet50\"  # enter model name\n",
        "N_EPOCHS = 32  # enter number of epochs\n",
        "COLAB_DATA_MODE = \"mount\" # Can be 'mount' (symlink) or 'copy'. Only used if on colab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Setup if using colab ###\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import shutil # Added import for shutil\n",
        "\n",
        "\n",
        "def in_colab() -> bool:\n",
        "    try:\n",
        "        import google.colab  # type: ignore\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "if in_colab():\n",
        "    from google.colab import drive  # type: ignore\n",
        "    print(\"Detected Colab. Mounting Drive...\")\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "    GITHUB_REPO = \"https://github.com/chihuangliu/microrobot-dl.git\"\n",
        "    REPO_PATH = \"/content/microrobot-dl\"\n",
        "    DRIVE_DATA_PATH = \"/content/drive/MyDrive/microrobot-dl-data/data\"  # where you uploaded your data on Drive\n",
        "\n",
        "    # Clone repo if missing\n",
        "    if not os.path.exists(REPO_PATH):\n",
        "        print(\"Cloning repository...\")\n",
        "        subprocess.check_call([\"git\", \"clone\", GITHUB_REPO, REPO_PATH])\n",
        "    else:\n",
        "        print(\"Repository already cloned:\", REPO_PATH)\n",
        "\n",
        "    # Install package (editable) from repo root\n",
        "    os.chdir(REPO_PATH)\n",
        "    print(\"Installing package from\", REPO_PATH)\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"uv\"])\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"uv\", \"pip\", \"install\", \"-e\", \".\"])\n",
        "\n",
        "    # Handle data based on COLAB_DATA_MODE\n",
        "    repo_data_path = os.path.join(REPO_PATH, \"data\")\n",
        "\n",
        "    # Clean up existing data path entry point first\n",
        "    if os.path.exists(repo_data_path):\n",
        "        if os.path.islink(repo_data_path):\n",
        "            print(f\"Removing existing symlink: {repo_data_path}\")\n",
        "            os.unlink(repo_data_path)\n",
        "        elif os.path.isdir(repo_data_path):\n",
        "            print(f\"Removing existing directory: {repo_data_path}\")\n",
        "            shutil.rmtree(repo_data_path)\n",
        "        else:\n",
        "            print(f\"Removing existing file/socket: {repo_data_path}\")\n",
        "            os.remove(repo_data_path)\n",
        "\n",
        "    if not os.path.exists(DRIVE_DATA_PATH):\n",
        "        print(\"Drive data path not found:\", DRIVE_DATA_PATH)\n",
        "        print(\"Upload your data to Drive and set DRIVE_DATA_PATH accordingly. No data will be linked/copied.\")\n",
        "    else:\n",
        "        if COLAB_DATA_MODE == \"copy\":\n",
        "            print(\"Copying Drive data from:\", DRIVE_DATA_PATH, \"to\", repo_data_path)\n",
        "            shutil.copytree(DRIVE_DATA_PATH, repo_data_path)\n",
        "            print(\"Data copied successfully.\")\n",
        "        elif COLAB_DATA_MODE == \"mount\":\n",
        "            print(\"Creating symlink from Drive data:\", DRIVE_DATA_PATH, \"to\", repo_data_path)\n",
        "            os.symlink(DRIVE_DATA_PATH, repo_data_path)\n",
        "            print(\"Data symlinked successfully.\")\n",
        "        else:\n",
        "            print(f\"Warning: Unknown COLAB_DATA_MODE '{COLAB_DATA_MODE}'. No data will be linked/copied.\")\n",
        "\n",
        "    # Change into notebooks/ so relative paths in the notebook continue to work\n",
        "    notebooks_dir = os.path.join(REPO_PATH, \"notebooks\")\n",
        "    if os.path.isdir(notebooks_dir):\n",
        "        os.chdir(notebooks_dir)\n",
        "        print(\"Changed working dir to notebooks:\", os.getcwd())\n",
        "    else:\n",
        "        print(\"No notebooks/ dir found; current working dir:\", os.getcwd())\n",
        "\n",
        "    if REPO_PATH not in sys.path:\n",
        "      sys.path.insert(0, REPO_PATH)\n",
        "else:\n",
        "    print(\"Not running on colab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULCnm9SvqPd6",
        "outputId": "ded51f67-7e6e-46ba-d2c2-637d7491297e"
      },
      "id": "ULCnm9SvqPd6",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected Colab. Mounting Drive...\n",
            "Mounted at /content/drive\n",
            "Cloning repository...\n",
            "Installing package from /content/microrobot-dl\n",
            "Creating symlink from Drive data: /content/drive/MyDrive/microrobot-dl-data/data to /content/microrobot-dl/data\n",
            "Data symlinked successfully.\n",
            "Changed working dir to notebooks: /content/microrobot-dl/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2041a0a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2041a0a5",
        "outputId": "fcdf6cdb-ef73-40ec-9f9b-3c1bd9a478d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from microrobot_dl.data_loader import ImageDataset2025\n",
        "from microrobot_dl.testset import get_imagedataset2025_test_set\n",
        "from microrobot_dl.data_loader import get_dataloaders\n",
        "from microrobot_dl.model import get_model\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "import sys # Import sys module\n",
        "\n",
        "torch.manual_seed(60648)\n",
        "\n",
        "# Setup device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif (\n",
        "    getattr(torch.backends, \"mps\", None) is not None\n",
        "    and torch.backends.mps.is_available()\n",
        "    and torch.backends.mps.is_built()\n",
        "):\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6d19ca96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d19ca96",
        "outputId": "896a3943-892f-40e3-cc0a-4be6eb5f9d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 2002\n",
            "Number of classes: 40\n",
            "Classes: ['P0_R0', 'P10_R0', 'P15_R0', 'P15_R15', 'P15_R30', 'P15_R45', 'P15_R5', 'P25_R0', 'P30_R0', 'P30_R10', 'P30_R15', 'P30_R30', 'P30_R45', 'P30_R5', 'P30_R60', 'P35_R0', 'P40_R0', 'P45_R0', 'P45_R10', 'P45_R15', 'P45_R30', 'P45_R45', 'P45_R5', 'P45_R60', 'P50_R0', 'P55_R0', 'P5_R0', 'P60_R0', 'P60_R10', 'P60_R15', 'P60_R30', 'P60_R45', 'P60_R5', 'P60_R60', 'P65_R0', 'P70_R0', 'P75_R0', 'P80_R0', 'P85_R0', 'P90_R0']\n"
          ]
        }
      ],
      "source": [
        "# Define Transforms\n",
        "# ResNet expects 224x224 input.\n",
        "# The dataset loads images as grayscale (\"L\").\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Load Dataset\n",
        "dataset = ImageDataset2025(\n",
        "    base_dir=\"../data/2025_Dataset\", mode=\"pose\", multi_label=False, transform=transform\n",
        ")\n",
        "\n",
        "num_classes = len(dataset.idx_to_label)\n",
        "print(f\"Total samples: {len(dataset)}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Classes: {dataset.idx_to_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "034aa402",
      "metadata": {
        "id": "034aa402"
      },
      "outputs": [],
      "source": [
        "test_set_info = get_imagedataset2025_test_set()\n",
        "test_indices = test_set_info[\"test_indices\"]\n",
        "test_indices = list(test_indices)\n",
        "test_set = set(test_indices)\n",
        "\n",
        "test_len = len(test_indices)\n",
        "train_val_len = len(dataset) - test_len\n",
        "\n",
        "all_indices = list(range(len(dataset)))\n",
        "train_val_indices = [i for i in all_indices if i not in test_set]\n",
        "\n",
        "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
        "train_val_dataset = torch.utils.data.Subset(dataset, train_val_indices)\n",
        "\n",
        "train_loader, test_loader, val_loader = get_dataloaders(\n",
        "    train_val_dataset,\n",
        "    test_dataset,\n",
        "    val_ratio=0.1,\n",
        "    train_batch_size=32,\n",
        "    test_batch_size=64,\n",
        "    val_batch_size=64,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a0ed378b",
      "metadata": {
        "id": "a0ed378b"
      },
      "outputs": [],
      "source": [
        "# Setup Model\n",
        "model = get_model(MODEL)\n",
        "\n",
        "# Modify the first convolutional layer to accept 1 channel (grayscale) instead of 3\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# Modify the final fully connected layer to match the number of classes\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c744c39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c744c39",
        "outputId": "34a65540-c6a3-4a9c-bb7f-d5314e1d7f42"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 51/51 [10:22<00:00, 12.21s/it]\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = f\"{MODEL}_pose_model_single_label\"\n",
        "MODEL_PATH = f\"../model/{MODEL_NAME}.pth\"\n",
        "train_losses, val_losses = [], []\n",
        "train_accs, val_accs = [], []\n",
        "best_val_loss = float(\"inf\")\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_acc = correct / total\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accs.append(epoch_acc)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss = val_running_loss / len(val_loader.dataset)\n",
        "    val_acc = val_correct / val_total\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(\n",
        "            {\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"val_acc\": val_acc,\n",
        "                \"val_loss\": val_loss,\n",
        "            },\n",
        "            MODEL_PATH,\n",
        "        )\n",
        "        print(f\"Saved best model to {MODEL_PATH} (Val Loss: {val_loss:.4f})\")\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1}/{N_EPOCHS} - Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} | Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "538c3e5c",
      "metadata": {
        "id": "538c3e5c"
      },
      "outputs": [],
      "source": [
        "# Plot Results\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accs, label=\"Train Acc\")\n",
        "plt.plot(val_accs, label=\"Val Acc\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training and Validation Accuracy\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe60bca",
      "metadata": {
        "id": "9fe60bca"
      },
      "outputs": [],
      "source": [
        "# Test Evaluation\n",
        "# Load best checkpoint\n",
        "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "model = model.to(device)\n",
        "if \"optimizer_state_dict\" in checkpoint:\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "\n",
        "epoch_loaded = checkpoint.get(\"epoch\")\n",
        "val_acc_loaded = checkpoint.get(\"val_acc\")\n",
        "val_loss_loaded = checkpoint.get(\"val_loss\")\n",
        "print(\n",
        "    f\"Loaded checkpoint from {MODEL_PATH} (epoch={epoch_loaded}, val_acc={val_acc_loaded}, val_loss={val_loss_loaded})\"\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = test_correct / test_total\n",
        "print(f\"Test Set Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0417632d",
      "metadata": {
        "id": "0417632d"
      },
      "outputs": [],
      "source": [
        "results = {\n",
        "    \"model_name\": MODEL_NAME,\n",
        "    \"accuracy\": test_accuracy,\n",
        "}\n",
        "\n",
        "out_path = os.path.join(\".eval\", f\"{MODEL_NAME}.json\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(f\"Saved results to {out_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73b4ce58",
      "metadata": {
        "id": "73b4ce58"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}