{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8260c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configs ###\n",
    "TEST_DATA_DIR = \"../data/2025_Dataset\"  # Put your test data directory here\n",
    "\n",
    "\n",
    "## The path to put the models\n",
    "POSE_CLASSIFICATION_MODEL_PATH = (\n",
    "    \"../model/resnet34_pose_model_single_label_augmented.pth\"\n",
    ")\n",
    "DEPTH_REGRESSION_MODEL_PATH = \"../model/resnet34_depth_augmented.pth\"\n",
    "\n",
    "## Model architecture in microrobot_dl.model.\n",
    "POSE_CLASSIFICATION_MODEL_ARCH = \"resnet34\"\n",
    "DEPTH_REGRESSION_MODEL_ARCH = \"resnet34\"\n",
    "\n",
    "## Task for the model in microrobot_dl.task. Don't change.\n",
    "POSE_CLASSIFICATION_MODEL_TASK = \"pose_single\"\n",
    "DEPTH_REGRESSION_MODEL_TASK = \"depth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d5de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on colab.\n"
     ]
    }
   ],
   "source": [
    "### Setup if using colab ###\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "COLAB_DATA_MODE = \"mount\"  # 'mount' or 'copy'\n",
    "DRIVE_DATA_PATH = \"/content/drive/MyDrive/microrobot-dl-data/data\"  # Where your data is stored in Google Drive\n",
    "GITHUB_REPO = \"https://github.com/chihuangliu/microrobot-dl.git\"\n",
    "REPO_PATH = \"/content/microrobot-dl\"\n",
    "\n",
    "\n",
    "def in_colab() -> bool:\n",
    "    try:\n",
    "        import google.colab  # type: ignore\n",
    "\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "if in_colab():\n",
    "    from google.colab import drive  # type: ignore\n",
    "\n",
    "    print(\"Detected Colab. Mounting Drive...\")\n",
    "    drive.mount(\"/content/drive\", force_remount=False)\n",
    "\n",
    "    if not os.path.exists(REPO_PATH):\n",
    "        print(\"Cloning repository...\")\n",
    "        subprocess.check_call([\"git\", \"clone\", GITHUB_REPO, REPO_PATH])\n",
    "    else:\n",
    "        print(\"Repository already cloned:\", REPO_PATH)\n",
    "\n",
    "    os.chdir(REPO_PATH)\n",
    "    print(\"Installing package from\", REPO_PATH)\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"uv\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"uv\", \"pip\", \"install\", \"-e\", \".\"])\n",
    "\n",
    "    repo_data_path = os.path.join(REPO_PATH, \"data\")\n",
    "\n",
    "    if os.path.exists(repo_data_path):\n",
    "        if os.path.islink(repo_data_path):\n",
    "            os.unlink(repo_data_path)\n",
    "        elif os.path.isdir(repo_data_path):\n",
    "            shutil.rmtree(repo_data_path)\n",
    "        else:\n",
    "            os.remove(repo_data_path)\n",
    "\n",
    "    if not os.path.exists(DRIVE_DATA_PATH):\n",
    "        print(\"Drive data path not found:\", DRIVE_DATA_PATH)\n",
    "    else:\n",
    "        if COLAB_DATA_MODE == \"copy\":\n",
    "            shutil.copytree(DRIVE_DATA_PATH, repo_data_path)\n",
    "        elif COLAB_DATA_MODE == \"mount\":\n",
    "            os.symlink(DRIVE_DATA_PATH, repo_data_path)\n",
    "\n",
    "    notebooks_dir = os.path.join(REPO_PATH, \"notebooks\")\n",
    "    if os.path.isdir(notebooks_dir):\n",
    "        os.chdir(notebooks_dir)\n",
    "\n",
    "    if REPO_PATH not in sys.path:\n",
    "        sys.path.insert(0, REPO_PATH)\n",
    "else:\n",
    "    print(\"Not running on colab.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec44aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from microrobot_dl.data_loader import ImageDataset2025\n",
    "from microrobot_dl.model import get_model\n",
    "from microrobot_dl.task import Task\n",
    "from microrobot_dl.inference import evaluate_model\n",
    "\n",
    "s\n",
    "# Setup device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif (\n",
    "    getattr(torch.backends, \"mps\", None) is not None\n",
    "    and torch.backends.mps.is_available()\n",
    "    and torch.backends.mps.is_built()\n",
    "):\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Common Transform\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f728ef97",
   "metadata": {},
   "source": [
    "# Pose Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b85235a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Pose Classification Evaluation ===\n",
      "Loaded pose model from ../model/resnet34_pose_model_single_label_augmented.pth\n",
      "Loaded pose model from ../model/resnet34_pose_model_single_label_augmented.pth\n",
      "Accuracy: 0.9795\n",
      "Loss: 0.0713\n",
      "Accuracy: 0.9795\n",
      "Loss: 0.0713\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Pose Classification Evaluation ===\")\n",
    "\n",
    "task = POSE_CLASSIFICATION_MODEL_TASK\n",
    "multi_label = task == Task.pose_multi\n",
    "\n",
    "# Load Dataset\n",
    "dataset_pose = ImageDataset2025(\n",
    "    base_dir=TEST_DATA_DIR,\n",
    "    mode=\"pose\",\n",
    "    multi_label=multi_label,\n",
    "    transform=transform_test,\n",
    ")\n",
    "\n",
    "test_loader_pose = DataLoader(dataset_pose, batch_size=64, shuffle=False)\n",
    "\n",
    "# Determine num_outputs\n",
    "if task == Task.pose_multi:\n",
    "    num_classes_p = len(dataset_pose.idx_to_label_p)\n",
    "    num_classes_r = len(dataset_pose.idx_to_label_r)\n",
    "    num_outputs = num_classes_p + num_classes_r\n",
    "else:\n",
    "    num_outputs = len(dataset_pose.idx_to_label)\n",
    "    num_classes_p = 0\n",
    "    num_classes_r = 0\n",
    "\n",
    "# Load Model (pose classification) - use configured arch variable\n",
    "model_pose = get_model(\n",
    "    POSE_CLASSIFICATION_MODEL_ARCH, num_outputs=num_outputs, in_channels=1\n",
    ")\n",
    "model_pose = model_pose.to(device)\n",
    "\n",
    "checkpoint = torch.load(POSE_CLASSIFICATION_MODEL_PATH, map_location=device)\n",
    "model_pose.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "print(f\"Loaded pose model from {POSE_CLASSIFICATION_MODEL_PATH}\")\n",
    "\n",
    "# Evaluate\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "results = evaluate_model(\n",
    "    model_pose,\n",
    "    test_loader_pose,\n",
    "    device,\n",
    "    task,\n",
    "    criterion=criterion,\n",
    "    num_classes_p=num_classes_p,\n",
    "    num_classes_r=num_classes_r,\n",
    "    multi_label=multi_label,\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "if task == Task.pose_multi:\n",
    "    print(f\"Accuracy P: {results['accuracy_p']:.4f}\")\n",
    "    print(f\"Accuracy R: {results['accuracy_r']:.4f}\")\n",
    "print(f\"Loss: {results['loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af30b9f",
   "metadata": {},
   "source": [
    "# Depth regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a5f85bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Depth Regression Evaluation ===\n",
      "Loaded depth model from ../model/resnet34_depth_augmented.pth\n",
      "Loaded depth model from ../model/resnet34_depth_augmented.pth\n",
      "RMSE: 0.0515\n",
      "RMSE: 0.0515\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Depth Regression Evaluation ===\")\n",
    "\n",
    "task = DEPTH_REGRESSION_MODEL_TASK\n",
    "\n",
    "# Load Dataset\n",
    "dataset_depth = ImageDataset2025(\n",
    "    base_dir=TEST_DATA_DIR,\n",
    "    mode=\"depth\",\n",
    "    transform=transform_test,\n",
    ")\n",
    "\n",
    "test_loader_depth = DataLoader(dataset_depth, batch_size=64, shuffle=False)\n",
    "\n",
    "# Load Model\n",
    "model_depth = get_model(DEPTH_REGRESSION_MODEL_ARCH, num_outputs=1, in_channels=1)\n",
    "model_depth = model_depth.to(device)\n",
    "\n",
    "checkpoint = torch.load(DEPTH_REGRESSION_MODEL_PATH, map_location=device)\n",
    "model_depth.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "print(f\"Loaded depth model from {DEPTH_REGRESSION_MODEL_PATH}\")\n",
    "\n",
    "# Evaluate\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "results = evaluate_model(\n",
    "    model_depth, test_loader_depth, device, task, criterion=criterion\n",
    ")\n",
    "\n",
    "print(f\"RMSE: {results['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e72a291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microrobot-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
